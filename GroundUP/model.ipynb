{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Harish Vasanth/Desktop/Machine-learning-projects/GroundUP/Datasets-20230714T035808Z-001/Datasets/Audios_split/\n",
      "['Machine13(Off)_1.mp3', 'Machine13(Off)_10.mp3', 'Machine13(Off)_11.mp3', 'Machine13(Off)_12.mp3', 'Machine13(Off)_13.mp3', 'Machine13(Off)_14.mp3', 'Machine13(Off)_15.mp3', 'Machine13(Off)_16.mp3', 'Machine13(Off)_17.mp3', 'Machine13(Off)_18.mp3', 'Machine13(Off)_19.mp3', 'Machine13(Off)_2.mp3', 'Machine13(Off)_20.mp3', 'Machine13(Off)_21.mp3', 'Machine13(Off)_22.mp3', 'Machine13(Off)_23.mp3', 'Machine13(Off)_24.mp3', 'Machine13(Off)_25.mp3', 'Machine13(Off)_26.mp3', 'Machine13(Off)_27.mp3', 'Machine13(Off)_28.mp3', 'Machine13(Off)_29.mp3', 'Machine13(Off)_3.mp3', 'Machine13(Off)_30.mp3', 'Machine13(Off)_31.mp3', 'Machine13(Off)_32.mp3', 'Machine13(Off)_33.mp3', 'Machine13(Off)_34.mp3', 'Machine13(Off)_35.mp3', 'Machine13(Off)_36.mp3', 'Machine13(Off)_37.mp3', 'Machine13(Off)_38.mp3', 'Machine13(Off)_39.mp3', 'Machine13(Off)_4.mp3', 'Machine13(Off)_40.mp3', 'Machine13(Off)_41.mp3', 'Machine13(Off)_42.mp3', 'Machine13(Off)_43.mp3', 'Machine13(Off)_44.mp3', 'Machine13(Off)_45.mp3', 'Machine13(Off)_46.mp3', 'Machine13(Off)_47.mp3', 'Machine13(Off)_48.mp3', 'Machine13(Off)_49.mp3', 'Machine13(Off)_5.mp3', 'Machine13(Off)_50.mp3', 'Machine13(Off)_51.mp3', 'Machine13(Off)_52.mp3', 'Machine13(Off)_53.mp3', 'Machine13(Off)_54.mp3', 'Machine13(Off)_55.mp3', 'Machine13(Off)_56.mp3', 'Machine13(Off)_57.mp3', 'Machine13(Off)_58.mp3', 'Machine13(Off)_59.mp3', 'Machine13(Off)_6.mp3', 'Machine13(Off)_60.mp3', 'Machine13(Off)_7.mp3', 'Machine13(Off)_8.mp3', 'Machine13(Off)_9.mp3', 'Machine13(On)_1.mp3', 'Machine13(On)_10.mp3', 'Machine13(On)_11.mp3', 'Machine13(On)_12.mp3', 'Machine13(On)_13.mp3', 'Machine13(On)_14.mp3', 'Machine13(On)_15.mp3', 'Machine13(On)_16.mp3', 'Machine13(On)_17.mp3', 'Machine13(On)_18.mp3', 'Machine13(On)_19.mp3', 'Machine13(On)_2.mp3', 'Machine13(On)_20.mp3', 'Machine13(On)_21.mp3', 'Machine13(On)_22.mp3', 'Machine13(On)_23.mp3', 'Machine13(On)_24.mp3', 'Machine13(On)_25.mp3', 'Machine13(On)_26.mp3', 'Machine13(On)_27.mp3', 'Machine13(On)_28.mp3', 'Machine13(On)_29.mp3', 'Machine13(On)_3.mp3', 'Machine13(On)_30.mp3', 'Machine13(On)_31.mp3', 'Machine13(On)_32.mp3', 'Machine13(On)_33.mp3', 'Machine13(On)_34.mp3', 'Machine13(On)_35.mp3', 'Machine13(On)_36.mp3', 'Machine13(On)_37.mp3', 'Machine13(On)_38.mp3', 'Machine13(On)_39.mp3', 'Machine13(On)_4.mp3', 'Machine13(On)_40.mp3', 'Machine13(On)_41.mp3', 'Machine13(On)_42.mp3', 'Machine13(On)_43.mp3', 'Machine13(On)_44.mp3', 'Machine13(On)_45.mp3', 'Machine13(On)_46.mp3', 'Machine13(On)_47.mp3', 'Machine13(On)_48.mp3', 'Machine13(On)_49.mp3', 'Machine13(On)_5.mp3', 'Machine13(On)_50.mp3', 'Machine13(On)_51.mp3', 'Machine13(On)_52.mp3', 'Machine13(On)_53.mp3', 'Machine13(On)_54.mp3', 'Machine13(On)_55.mp3', 'Machine13(On)_56.mp3', 'Machine13(On)_57.mp3', 'Machine13(On)_58.mp3', 'Machine13(On)_59.mp3', 'Machine13(On)_6.mp3', 'Machine13(On)_60.mp3', 'Machine13(On)_7.mp3', 'Machine13(On)_8.mp3', 'Machine13(On)_9.mp3']\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "import os\n",
    "dir_path = r'C:/Users/Harish Vasanth/Desktop/Machine-learning-projects/GroundUP/Datasets-20230714T035808Z-001/Datasets/Audios_split/' ## Add path to your folder\n",
    "for path, _, files in os.walk(dir_path):\n",
    "    # check if current path is a file\n",
    "    print(path)\n",
    "    print(files)\n",
    "    res.append(files)\n",
    "\n",
    "\n",
    "off_files =[]\n",
    "on_files = []\n",
    "for file in res[0] :\n",
    "        if \"(Off)\" in str(file):\n",
    "              off_files.append(file)\n",
    "        else :\n",
    "              on_files.append(file)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "open() got an unexpected keyword argument 'newline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdata.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file: \u001b[39m## add your csv file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m      writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mwriter(file)\n\u001b[0;32m      4\u001b[0m      writer\u001b[39m.\u001b[39mwriterow([\u001b[39m\"\u001b[39m\u001b[39mAudio\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mState\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mNumericState\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: open() got an unexpected keyword argument 'newline'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('data.csv', 'w', newline='') as file: ## add your csv file\n",
    "     writer = csv.writer(file)\n",
    "     writer.writerow([\"Audio\",\"State\",\"NumericState\"])\n",
    "\n",
    "     for row in off_files :\n",
    "               writer.writerow([row, \"off\",0])\n",
    "     for row in on_files :\n",
    "               writer.writerow([row, \"on\",1])\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Audio</th>\n",
       "      <th>State</th>\n",
       "      <th>NumericState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine13(Off)_1.mp3</td>\n",
       "      <td>off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine13(Off)_10.mp3</td>\n",
       "      <td>off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine13(Off)_11.mp3</td>\n",
       "      <td>off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine13(Off)_12.mp3</td>\n",
       "      <td>off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine13(Off)_13.mp3</td>\n",
       "      <td>off</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Machine13(On)_6.mp3</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Machine13(On)_60.mp3</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Machine13(On)_7.mp3</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Machine13(On)_8.mp3</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Machine13(On)_9.mp3</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Audio State  NumericState\n",
       "0     Machine13(Off)_1.mp3   off             0\n",
       "1    Machine13(Off)_10.mp3   off             0\n",
       "2    Machine13(Off)_11.mp3   off             0\n",
       "3    Machine13(Off)_12.mp3   off             0\n",
       "4    Machine13(Off)_13.mp3   off             0\n",
       "..                     ...   ...           ...\n",
       "115    Machine13(On)_6.mp3    on             1\n",
       "116   Machine13(On)_60.mp3    on             1\n",
       "117    Machine13(On)_7.mp3    on             1\n",
       "118    Machine13(On)_8.mp3    on             1\n",
       "119    Machine13(On)_9.mp3    on             1\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_on_off(audiofile : str, machine: str):\n",
    "    assert machine[0] == \"M\"\n",
    "    y, sr = librosa.load(audiofile, sr=None)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=8).T,axis=0)\n",
    "    mfcc_0 = list(mfcc)[0]\n",
    "    if machine in mfcc_thresh_dict:\n",
    "        threshold = mfcc_thresh_dict[machine]\n",
    "    else:\n",
    "        threshold = -515\n",
    "\n",
    "    if mfcc_0 > threshold:\n",
    "        status = \"ON\"\n",
    "    else:\n",
    "        status = \"OFF\"\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv') # Alter accordingly\n",
    "X = data['Audio']\n",
    "y = data[['State','NumericState']]\n",
    "audio_dataset_path= dir_path\n",
    "#Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    return (sig, sr)\n",
    "\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name) \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m### Now we iterate through every audio file and extract features \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m### using Mel-Frequency Cepstral Coefficients\u001b[39;00m\n\u001b[0;32m      3\u001b[0m extracted_features\u001b[39m=\u001b[39m[]\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m index_num,row \u001b[39min\u001b[39;00m tqdm(data\u001b[39m.\u001b[39;49miterrows()):\n\u001b[0;32m      6\u001b[0m     file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(audio_dataset_path \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(row[\u001b[39m\"\u001b[39m\u001b[39mAudio\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m      7\u001b[0m     final_class_labels\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mNumericState\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "\n",
    "for index_num,row in tqdm(data.iterrows()):\n",
    "    file_name = os.path.join(audio_dataset_path + str(row[\"Audio\"]))\n",
    "    final_class_labels=row[\"NumericState\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])\n",
    "\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train  Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "len(X_train) +len(X_val) +len(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_val,y_val)    \n",
    "clf.score(X_test,y_test)    \n",
    "\n",
    "y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         8\\n           1       1.00      1.00      1.00        16\\n\\n    accuracy                           1.00        24\\n   macro avg       1.00      1.00      1.00        24\\nweighted avg       1.00      1.00      1.00        24\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test,y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
