{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "sheet_delimiter": true
    }
   },
   "source": [
    "# SC1015 Group 7 Project \n",
    "## Problem definition: How can we predict a movie's rating solely based on its review?\n",
    "Using sentiment analysis with a Multi-layer Perceptron Neural Network model from sklearn to analyse the language of a movie review to give an positive or negative rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard helper libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Some machine learning libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords') # to download nltk stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Reading the IMDb review CSV data\n",
    " #### <font color=#fc2d1e>IMPORTANT: During cleaning data process, please skip ahead and run IMDB_cleaned_data.csv located below after \"Tokenisation of data to build a classification model\" to avoid waiting an unnecessarily long time for the entire cleaning process to finish.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read imdb review data into a dataframe\n",
    "data = pd.read_csv('./datasets/imdb_master.csv', encoding=\"ISO-8859-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Data visualisation to get an intuitive idea of what we are working with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words in positive and negative reviews visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Some data visualisation of words in negative and positive reviews\n",
    "negdatawords = data[data['label'] == 'neg']\n",
    "posdatawords = data[data['label'] == 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Visualising negative reviews words\n",
    "cloud = WordCloud(width=800, height=600).generate(\" \".join(negdatawords['review']))\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(label=\"Negative reviews words\", fontsize=20, color=\"green\")\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Visualising positive review words\n",
    "cloud = WordCloud(width=800, height=600).generate(\" \".join(posdatawords['review'])) # join function can help merge all words into one string. \" \" means space can be a sep between words.\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(label=\"Positive reviews words\", fontsize=20, color=\"green\")\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of positive, negative, and unlabelled data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'neg'), Text(1, 0, 'pos'), Text(2, 0, 'unsup')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of positive, negative and unlabelled data\n",
    "maindata = data[['review','label']]\n",
    "ax = maindata.groupby('label').count().plot(kind='bar', title='Distribution of data', legend=False)\n",
    "ax.set_xticklabels(['neg','pos','unsup'], rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "Comment: \\\n",
    "Fairly equal distribution of data so far but still needs some cleanup. As seen above, the postive and negative datasets both have common words such as 'film' and 'movie' that would be redundant in analysing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Doing some initial data cleaning and preparation\n",
    "1. Separated 'unsup' label from the rest\n",
    "2. Removed train test label for random train and test\n",
    "3. Remove punctuation marks, make all letters lowercase, etc.\n",
    "4. **<font color=#fc2d1e>As there is a large amount of data (10000 entries), we will export the cleaned data as a CSV file and re-import it to save on the cleaning time. There is no actual need to run the subsequent codes anymore.</font>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Removing useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review    0\n",
      "label     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Removed train test label, and the other labels\n",
    "cleaned_data = data.drop(columns=['type', 'file', 'Unnamed: 0'])\n",
    "print(cleaned_data.isnull().sum()) # just to check that there's no NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Make the reviews lowercase and without punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-c4513ac3038c>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cleaned_data[\"cleaned_review\"] = cleaned_data['cleaned_review'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "# Make letters lowercase and remove punctuations and putting them inside new dataset called 'review'\n",
    "cleaned_data[\"cleaned_review\"] = cleaned_data[\"review\"].str.lower()\n",
    "cleaned_data[\"cleaned_review\"] = cleaned_data['cleaned_review'].str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   review   label  \\\n",
      "count                                              100000  100000   \n",
      "unique                                              98469       3   \n",
      "top     Am not from America, I usually watch this show...   unsup   \n",
      "freq                                                    6   50000   \n",
      "\n",
      "                                           cleaned_review  \n",
      "count                                              100000  \n",
      "unique                                              98467  \n",
      "top     am not from america i usually watch this show ...  \n",
      "freq                                                    6  \n",
      "\n",
      "Dimensions: (100000, 3)\n",
      "\n",
      "review            object\n",
      "label             object\n",
      "cleaned_review    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Take a peek at the data\n",
    "print(cleaned_data.describe())\n",
    "print(f\"\\nDimensions: {cleaned_data.shape}\\n\")\n",
    "print(cleaned_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Tokenisation of data in order to build a classification model\n",
    "#### It means that we are going to make each word into a token to feed into the ML model, instead of feeding the model a string.\n",
    "Process includes:\n",
    "\n",
    "1. Made words into stem form\n",
    "2. Removed stop words (frequently used English words)\n",
    "3. Tokenised sentences into arrays of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import PorterStemmer as PS\\n\\nps = PS()\\n\\nstop_words = set(stopwords.words('english'))\\n\\n# Stemming words and removing stop words\\ncleaned_data['tokenised_review'] = [' '.join([ps.stem(y) for y in x.split() if y not in stop_words]) for x in cleaned_data['cleaned_review']]\\n\\n# Tokenising sentences into array of words\\n# This step is not really that necessary since we are going to vectorise\\n# this using a function from sklearn in the next part\\ncleaned_data['tokenised_review'] = cleaned_data['tokenised_review'].apply(lambda x: x[:].split(' '))\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenise the sentence into list of words (removed stopwords)\n",
    "# Don't run this I made a cleaned csv file, unless you are very free, or want to take a break for ~10 minutes\n",
    "\"\"\"\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer as PS\n",
    "\n",
    "ps = PS()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Stemming words and removing stop words\n",
    "cleaned_data['tokenised_review'] = [' '.join([ps.stem(y) for y in x.split() if y not in stop_words]) for x in cleaned_data['cleaned_review']]\n",
    "\n",
    "# Tokenising sentences into array of words\n",
    "# This step is not really that necessary since we are going to vectorise\n",
    "# this using a function from sklearn in the next part\n",
    "cleaned_data['tokenised_review'] = cleaned_data['tokenised_review'].apply(lambda x: x[:].split(' '))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cleaned data csv could be found here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokenised_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>once again mr costner has dragged out a movie ...</td>\n",
       "      <td>['mr', 'costner', 'drag', 'movi', 'far', 'long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>this is an example of why the majority of acti...</td>\n",
       "      <td>['exampl', 'major', 'action', 'film', 'gener',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>first of all i hate those moronic rappers who ...</td>\n",
       "      <td>['first', 'hate', 'moron', 'rapper', 'couldnt'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>not even the beatles could write songs everyon...</td>\n",
       "      <td>['even', 'beatl', 'could', 'write', 'song', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>['brass', 'pictur', 'movi', 'fit', 'word', 're...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unzip the csv file if not unzipped already, uncomment line below\n",
    "# !unzip imdb_master_cleaned.zip \n",
    "cleaned_data = pd.read_csv(\"./datasets/imdb_master_cleaned.csv\")\n",
    "cleaned_data.head()"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "REACTIVE",
   "package_manager": "pip",
   "packages": [
    {
     "name": "nltk",
     "source": "PIP",
     "version": "3.7"
    },
    {
     "name": "pandarallel",
     "source": "PIP"
    },
    {
     "name": "wordcloud",
     "source": "PIP",
     "version": "1.8.1"
    },
    {
     "name": "textblob",
     "source": "PIP"
    }
   ],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
